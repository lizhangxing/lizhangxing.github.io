{"meta":{"title":"pusheng","subtitle":"","description":"","author":"普生","url":"http://localhost:4000","root":"/"},"pages":[],"posts":[{"title":"视频循迹】","slug":"视频循迹】","date":"2023-10-22T11:49:08.000Z","updated":"2023-12-18T13:51:23.133Z","comments":true,"path":"post/40312.html","link":"","permalink":"http://localhost:4000/post/40312.html","excerpt":"","text":"","categories":[],"tags":[]},{"title":"jetson_nano_control","slug":"jetson-nano-control","date":"2023-10-17T02:18:09.000Z","updated":"2023-12-18T13:55:37.261Z","comments":true,"path":"post/6629.html","link":"","permalink":"http://localhost:4000/post/6629.html","excerpt":"","text":"IIC与编码电机通讯i2cdetect -y -r -a 1查找设备地址； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import smbus#需要安装的库文件import timeI2C_ADDR = 0x34 # I2C设备地址ADC_BAT_ADDR = 0 # 电压地址MOTOR_TYPE_ADDR = 20 # 编码电机类型设置MOTOR_ENCODER_POLARITY_ADDR = 21 # 设置编码方向极性MOTOR_FIXED_PWM_ADDR = 31 # 固定PWM控制MOTOR_FIXED_SPEED_ADDR = 51 # 固定转速控制MOTOR_ENCODER_TOTAL_ADDR = 60 # 4个编码电机各自的总脉冲值MOTOR_TYPE_WITHOUT_ENCODER = 0MOTOR_TYPE_TT = 1 #TT 编码电机MOTOR_TYPE_N20 = 2 #N20 编码电机MOTOR_TYPE_JGB37_520_12V_110RPM = 3 #磁环每转是 44 个脉冲 减速比:90默认# 初始化I2C总线bus = smbus.SMBus(1)#写入字节def wire_write_byte(val): try: bus.write_byte(I2C_ADDR, val) return True except IOError: return False#将数据组写入到指定寄存器的i2c设备def wire_write_data_array(reg, val): try: bus.write_i2c_block_data(I2C_ADDR, reg, val) return True except IOError: return False#从指定寄存器读取一个字节的数据def wire_read_data_byte(reg): try: val = bus.read_byte_data(I2C_ADDR, reg) return val except IOError: return None# 从指定寄存器开始读取指定长度的数据数组。def wire_read_data_array(reg, length): try: data = bus.read_i2c_block_data(I2C_ADDR, reg, length) return data except IOError: return Nonedef main(): # 初始化 bus.open(1) wire_write_data_array(MOTOR_TYPE_ADDR, [MOTOR_TYPE_TT]) # 设置电机类型 wire_write_data_array(MOTOR_ENCODER_POLARITY_ADDR, [1]) # 设置编码器极性 # 控制电机 # 速度 p1 = [50, 50, 50, 50] p2 = [-50, -50, -50, -50] s1 = [2, 2, 2, 2] s2 = [-2, -2, -2, -2] wire_write_data_array(MOTOR_FIXED_SPEED_ADDR, p1) # 设置电机前进速度 # wire_write_data_array(MOTOR_FIXED_PWM_ADDR, p1) # 可以选择使用PWM控制电机 wire_write_data_array(MOTOR_FIXED_SPEED_ADDR, s1) # 设置电机后退速度 print(&quot;电机控制中...&quot;) time.sleep(0.7) wire_write_data_array(MOTOR_FIXED_SPEED_ADDR, p2) wire_write_data_array(MOTOR_FIXED_SPEED_ADDR, s2) print(&quot;电机控制完成&quot;) # 读取电压 voltage_data = wire_read_data_array(ADC_BAT_ADDR, 2) voltage = voltage_data[0] + (voltage_data[1] &lt;&lt; 8) print(&quot;电压:&quot;, voltage, &quot;mV&quot;) # 读取电机累积转动量 encode_total_data = wire_read_data_array(MOTOR_ENCODER_TOTAL_ADDR, 16) encode_total = [ int.from_bytes(encode_total_data[i:i+4], byteorder=&#x27;little&#x27;) for i in range(0, len(encode_total_data), 4) ] print(&quot;电机累积转动量:&quot;, encode_total)if __name__ == &quot;__main__&quot;: main() 手柄操控：查询手柄映射关系：1：使用Pygame的pygame.joystick.Joystick对象的get_button方法来动态检查按钮是否按下，并查找其按钮编号。以下是一个示例代码： 1234567891011121314151617181920212223242526272829303132import pygame# 初始化pygamepygame.init()# 设置手柄joystick = pygame.joystick.Joystick(0)joystick.init()# 主循环running = Truewhile running: for event in pygame.event.get(): if event.type == pygame.QUIT: running = False # 获取按钮状态 button_0_state = joystick.get_button(0) button_1_state = joystick.get_button(1) # 检查按钮状态并执行操作 if button_0_state == 1: print(&quot;Button 0 is pressed&quot;) # 执行相应操作 if button_1_state == 1: print(&quot;Button 1 is pressed&quot;) # 执行相应操作# 清理pygame.quit() 在这个示例中，joystick.get_button(0) 返回按钮0的状态，1表示按下，0表示未按下。你可以类似地检查其他按钮的状态。 2：使用测试工具进行测试：你可以使用jstest命令行工具来测试手柄并获取按钮的编号。首先，确保手柄已连接到Jetson设备。然后，打开终端并执行以下命令 12sudo apt-get install joystickjstest /dev/input/js0#手柄连接后会在文件夹中生成js0文件若有多个手柄则会生成多个js文件 这将启动手柄测试工具，并在终端中显示按钮和轴的状态。按下按钮时，你将看到相关的按钮编号。这可以帮助你确定哪个按钮对应哪个编号。 一旦你确定了按钮的编号，你可以在你的Pygame代码中使用相应的编号来处理按钮按下事件。","categories":[],"tags":[{"name":"jetson_nano","slug":"jetson-nano","permalink":"http://localhost:4000/tags/jetson-nano/"}]},{"title":"yolo早停","slug":"yolo早停","date":"2023-08-28T01:09:16.000Z","updated":"2023-12-18T13:51:23.129Z","comments":true,"path":"post/1169.html","link":"","permalink":"http://localhost:4000/post/1169.html","excerpt":"","text":"yolov7自动停止（设置patience）且输出最优模型时的PR图（test best.py）早停的意义一、早停法简介（Early Stopping）当我们训练深度学习神经网络的时候通常希望能获得最好的泛化性能（generalization performance，即可以很好地拟合数据）。但是所有的标准深度学习神经网络结构如全连接多层感知机都很容易过拟合：当网络在训练集上表现越来越好，错误率越来越低的时候，实际上在某一刻，它在测试集的表现已经开始变差。 模型的泛化能力通常使用模型在验证数据集（validation set）上的表现来评估。随着网络的优化，我们期望的理想中的泛化错误如图1所示。即当模型在训练集上的误差降低的时候，其在验证集上的误差表现不会变差。反之，当模型在训练集上表现很好，在验证集上表现很差的时候，我们认为模型出现了过拟合（overfitting）的情况。 解决过拟合问题有两个方向：降低参数空间的维度或者降低每个维度上的有效规模（effective size）。降低参数数量的方法包括greedy constructive learning、剪枝和权重共享等。降低每个参数维度的有效规模的方法主要是正则化，如权重衰变（weight decay）和早停法（early stopping）等。 早停法是一种被广泛使用的方法，在很多案例上都比正则化的方法要好。图1是我们经常看到论文中出现的图，也是使用早停法出现的一个结果。其基本含义是在训练中计算模型在验证集上的表现，当模型在验证集上的表现开始下降的时候，停止训练，这样就能避免继续训练导致过拟合的问题。其主要步骤如下： 原始的训练数据集划分成训练集和验证集 只在训练集上进行训练，并每个一个周期计算模型在验证集上的误差，例如，每15次epoch（mini batch训练中的一个周期） 当模型在验证集上的误差比上一次训练结果差的时候停止训练 使用上一次迭代结果中的参数作为模型的最终参数 然而，在现实中，模型在验证集上的误差不会像上图那样平滑，而是像下图一样： 也就是说，模型在验证集上的表现可能咱短暂的变差之后有可能继续变好。上图在训练集迭代到400次的时候出现了16个局部最低。其中有4个最低值是它们所在位置出现的时候的最低点。其中全局最优大约出现在第205次迭代中。首次出现最低点是第45次迭代。相比较第45次迭代停止，到第400次迭代停止的时候找出的最低误差比第45次提高了1.1%，但是训练时间大约是前者的7倍。 但是，并不是所有的误差曲线都像上图一样，有可能在出现第一次最低点之后，后面再也没有比当前最低点更低的情况了。所以我们看到，早停法主要是训练时间和泛化错误之间的权衡。尽管如此，也有某些停止标准也可以帮助我们寻找更好的权衡。 二、如何使用早停法我们需要一个停止的标准来实施早停法，因此，我们希望它可以产生最低的繁华错误，同时也可以有最好的性价比，即给定泛化错误下的最小训练时间 2.1、停止标准简介停止标准有很多，也很灵活，大约有三种。在给出早停法的具体标准之前，我们先确定一下符号。假设我们使用 **E **作为训练算法的误差函数，那么 Etr(t) 是训练数据上的误差，Ete(t) 是测试集上的误差。实际情况下我们并不能知道泛化误差，因此我们使用验证集误差来估计它。 第一类停止标准(Gl) 我们定义一个新变量叫泛化损失（generalization loss），它描述的是在当前迭代周期t中，泛化误差相比较目前的最低的误差的一个增长率 较高的泛化损失显然是停止训练的一个候选标准，因为它直接表明了过拟合。 第二类停止标准(PQ) 然而，当训练的速度很快的时候，我们可能希望模型继续训练。因为如果训练错误依然下降很快，那么泛化损失有很大概率被修复。我们通常会假设过拟合只会在训练错误降低很慢的时候出现。在这里，我们定义一个k周期，以及基于周期的一个新变量度量进展（measure progress） 它表达的含义是，当前的指定迭代周期内的平均训练错误比该期间最小的训练错误大多少。注意，当训练过程不稳定的时候，这个measure progress结果可能很大，其中训练错误会变大而不是变小。实际中，很多算法都由于选择了不适当的较大的步长而导致这样的抖动。除非全局都不稳定，否则在较长的训练之后，measure progress结果趋向于0（其实这个就是度量训练集错误在某段时间内的平均下降情况）。由此，我们引入了第二个停止标准，即泛化损失和进展的商PQα大于指定值的时候停止，即GL(t)&#x2F;Pi(t)&gt;0. 第三类停止标准(up)第三类停止标准则完全依赖于泛化错误的变化，即当泛化错误在连续s个周期内增长的时候停止（UP）。 当验证集错误在连续s个周期内出现增长的时候，我们假设这样的现象表明了过拟合，它与错误增长了多大独立。这个停止标准可以度量局部的变化，因此可以用在剪枝算法中，即在训练阶段，允许误差可以比前面最小值高很多时候保留。 2.2、停止标准选择规则一般情况下，“较慢”的标准会相对而言在平均水平上表现略好，可以提高泛化能力。然而，这些标准需要较长的训练时间。其实，总体而言，这些标准在系统性的区别很小。主要选择规则包括： 除非较小的提升也有很大价值，负责选择较快的停止标准 为了最大可能找到一个好的方案，使用GL标准 为了最大化平均解决方案的质量，如果网络只是过拟合了一点点，可以使用PQ标准，否则使用UP标准 注意，目前并没有理论上可以证明那种停止标准较好，所以都是实验的数据。后续我们再介绍一下实验结果。 步骤1：在utils文件夹下的torch_utils.py里添加如下class 123456789101112131415161718192021class EarlyStopping: # YOLOv5 simple early stopper def __init__(self, patience=30): self.best_fitness = 0.0 # i.e. mAP self.best_epoch = 0 self.patience = patience or float(&#x27;inf&#x27;) # epochs to wait after fitness stops improving to stop self.possible_stop = False # possible stop may occur next epoch def __call__(self, epoch, fitness): if fitness &gt;= self.best_fitness: # &gt;= 0 to allow for early zero-fitness stage of training self.best_epoch = epoch self.best_fitness = fitness delta = epoch - self.best_epoch # epochs without improvement self.possible_stop = delta &gt;= (self.patience - 1) # possible stop may occur next epoch stop = delta &gt;= self.patience # stop training if patience exceeded if stop: logger.info(f&#x27;Stopping training early as no improvement observed in last &#123;self.patience&#125; epochs. &#x27; f&#x27;Best results observed at epoch &#123;self.best_epoch&#125;, best model saved as best.pt.\\n&#x27; f&#x27;To update EarlyStopping(patience=&#123;self.patience&#125;) pass a new patience value, &#x27; f&#x27;i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.&#x27;) return stop 步骤2：在train.py前面添加模块 1from util.torch_utils import EarlyStopping 步骤3：在train.py文件里大概第三百行start training中scaler变量下面添加如下两行 12stopper: EarlyStoppingstopper, stop = EarlyStopping(patience=opt.patience), False 步骤4：在train.py文件里大概450行的位置，#Save model上方加入如下代码（并将原来的#Update best mAP部分删除） 123456# Update best mAPfi = fitness(np.array(results).reshape(1, -1)) # weighted combination of [P, R, mAP@.5, mAP@.5-.95]stop = stopper(epoch=epoch, fitness=fi) # early stop checkif fi &gt; best_fitness: best_fitness = fiwandb_logger.end_epoch(best_result=best_fitness == fi) 步骤5：在train.py文件里大概490行的位置，#end epoch上方加入如下代码 12345678# EarlyStoppingif rank != -1: # if DDP training broadcast_list = [stop if rank == 0 else None] dist.broadcast_object_list(broadcast_list, 0) # broadcast &#x27;stop&#x27; to all ranks if rank != 0: stop = broadcast_list[0]if stop: break # must break all DDP ranks 步骤6：在train.py文件里大概580行的位置，加入一行 12parser.add_argument(&#x27;--patience&#x27;, type=int, default=100, help=&#x27;EarlyStopping patience (epochs without improvement)&#x27;) 步骤7：在train.py文件里大概425行的位置，将原先# Calculate mAP的部分更改为 1234567891011121314if not opt.notest or final_epoch: # Calculate mAP wandb_logger.current_epoch = epoch + 1 results, maps, times = test.test(data_dict, batch_size=batch_size * 2, imgsz=imgsz_test, model=ema.ema, single_cls=opt.single_cls, dataloader=testloader, save_dir=save_dir, verbose=nc &lt; 50 , plots=False, wandb_logger=wandb_logger, compute_loss=compute_loss, is_coco=is_coco) 步骤8：在train.py文件里大概500行的位置，将原先# Test best.pt的部分更改为 1234567891011121314151617# Test best.ptlogger.info(&#x27;%g epochs completed in %.3f hours.\\n&#x27; % (epoch - start_epoch + 1, (time.time() - t0) / 3600))results, _, _ = test.test(opt.data, batch_size=batch_size * 2, imgsz=imgsz_test, conf_thres=0.001, iou_thres=0.7, model=attempt_load(best, device).half(), single_cls=opt.single_cls, dataloader=testloader, verbose=nc &lt; 50, save_dir=save_dir, save_json=True, plots=plots, wandb_logger=wandb_logger, compute_loss=compute_loss, is_coco=is_coco) 步骤9：在test.py（注意换文件啦！）里大概293行的地方将iou-thres的默认值更改为0.7 1parser.add_argument(&#x27;--iou-thres&#x27;, type=float, default=0.7, help=&#x27;IOU threshold for NMS&#x27;) 在第26行的地方将iou-thres的值更改为0.7 1iou_thres=0.7, # for NMS Q","categories":[],"tags":[{"name":"yolo","slug":"yolo","permalink":"http://localhost:4000/tags/yolo/"}]},{"title":"yolo剪枝","slug":"yolo改进","date":"2023-08-26T11:40:53.000Z","updated":"2023-12-18T13:51:23.127Z","comments":true,"path":"post/33024.html","link":"","permalink":"http://localhost:4000/post/33024.html","excerpt":"","text":"yolov7剪枝环境torch_pruning ==1.2.2 thop 参数解释12#pruningparser.add_argument(&#x27;--prune_method&#x27;, type=str, default=None, help=&#x27;prune method&#x27;)#定义方法如random，l1等 方法 group_sl growing_reg&#96;暂时不可用对yolov7的spp层不能 存在sparsity_learning = True就需要稀疏训练 1parser.add_argument(&#x27;--speed_up&#x27;, type=float, default=2.0, help=&#x27;speed up&#x27;) 保证速度 为2.0时就是当原模型与现模型的计算量的比值为2时停止剪枝 12345678parser.add_argument(&quot;--reg&quot;, type=float, default=5e-4)#稀疏话参数学习率parser.add_argument(&quot;--delta_reg&quot;, type=float, default=1e-4, help=&#x27;for growing regularization&#x27;)#正则化参数parser.add_argument(&quot;--sl_hyp&quot;, type=str, default=&#x27;data/hyp.scratch.sl.yaml&#x27;, help=&#x27;hyperparameters path for sparsity learning&#x27;)#稀疏训练的超参数可以调parser.add_argument(&quot;--sl_epochs&quot;, type=int, default=100)parser.add_argument(&quot;--sl_model&quot;, type=str, default=&quot;&quot;, help=&#x27;sparsity learning trained model weights&#x27;) 稀疏训练不能使用AMP混合精度训练,将 如何跳过某些层级最后一层的输出不能减（可以减最后一层的内的卷积操作） attention操作需要跳过· 跳过那个层级需要导入对应的模块 12345678910ignored_layers.append(model.model[77])#跳过cfg列表中对应的层for cfg/training/yolov7-tiny-prune.yaml for k, m in model.named_modules(): if isinstance(m, TSCODE_Detect):#判断t ignored_layers.append(m.m_cls)#跳过层 ignored_layers.append(m.m_reg) ignored_layers.append(m.m_conf) if isinstance(m, Yolov7_Tiny_E_ELAN_Attention): ignored_layers.append(m.att)","categories":[],"tags":[{"name":"yolo","slug":"yolo","permalink":"http://localhost:4000/tags/yolo/"}]},{"title":"yolo计算","slug":"yolo计算","date":"2023-08-17T06:29:25.000Z","updated":"2023-12-18T13:51:23.132Z","comments":true,"path":"post/30962.html","link":"","permalink":"http://localhost:4000/post/30962.html","excerpt":"","text":"yolo值的计算YOLOv5-不同map值计算解决思路1，解决关键代码在276行,如下加粗部分 2，打印ap的值：结果如下图所示：输出结果12行，代表12个类别；每一行有10个数，分别代表ap[50, 55, 60, 65, 70, 75, 80, 85, 90, 95], 所以ap75=ap[5], map75=ap.mean[:,5] 修改部分​ 190-191行 12345678# 修改前s = (&#x27;%22s&#x27; + &#x27;%11s&#x27; * 6) % (&#x27;Class&#x27;, &#x27;Images&#x27;, &#x27;Instances&#x27;, &#x27;P&#x27;, &#x27;R&#x27;, &#x27;mAP50&#x27;, &#x27;mAP50-95&#x27;)tp, fp, p, r, f1, mp, mr, map50, ap50, map = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0# 修改后s = (&#x27;%22s&#x27; + &#x27;%11s&#x27; * 7) % (&#x27;Class&#x27;, &#x27;Images&#x27;, &#x27;Instances&#x27;, &#x27;P&#x27;, &#x27;R&#x27;, &#x27;mAP50&#x27;, &#x27;mAP75&#x27;, &#x27;mAP50-95&#x27;)tp, fp, p, r, f1, mp, mr, map50, map75, ap50, map = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ​ 276-277行 12345678# 修改前ap50, ap = ap[:, 0], ap.mean(1) # AP@0.5, AP@0.5:0.95mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()# 修改后ap50, ap75, ap = ap[:, 0], ap[:, 5], ap.mean(1) # AP@0.5, AP@0.75, AP@0.5:0.95mp, mr, map50, map75, map = p.mean(), r.mean(), ap50.mean(), ap75.mean(), ap.mean() ​ 281-282行 12345678# 修改前pf = &#x27;%22s&#x27; + &#x27;%11i&#x27; * 2 + &#x27;%11.3g&#x27; * 4 # print formatLOGGER.info(pf % (&#x27;all&#x27;, seen, nt.sum(), mp, mr, map50, map))# 修改后pf = &#x27;%22s&#x27; + &#x27;%11i&#x27; * 2 + &#x27;%11.3g&#x27; * 5 # print formatLOGGER.info(pf % (&#x27;all&#x27;, seen, nt.sum(), mp, mr, map50, map75, map)) ​ 289行 123456# 修改前LOGGER.info(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))# 修改后LOGGER.info(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap75[i], ap[i])) ​ 300行 123456# 修改前callbacks.run(&#x27;on_val_end&#x27;, nt, tp, fp, p, r, f1, ap, ap50, ap_class, confusion_matrix)# 修改后callbacks.run(&#x27;on_val_end&#x27;, nt, tp, fp, p, r, f1, ap, ap50, ap75, ap_class, confusion_matrix) ​ 324行 123456# 修改前map, map50 = eval.stats[:2] # update results (mAP@0.5:0.95, mAP@0.5)# 修改后map, map50, map75 = eval.stats[:3] # update results (mAP@0.5:0.95, mAP@0.75，mAP@0.5) ​ 336行 123456# 修改前return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t# 修改后return (mp, mr, map50, map75, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t 运行val.py","categories":[],"tags":[{"name":"yolo","slug":"yolo","permalink":"http://localhost:4000/tags/yolo/"}]},{"title":"学习率调整策略","slug":"xuexilv","date":"2023-08-16T02:20:53.000Z","updated":"2023-08-26T11:40:13.265Z","comments":true,"path":"post/58585.html","link":"","permalink":"http://localhost:4000/post/58585.html","excerpt":"","text":"学习率调整策略——lr_scheduler学习率是深度学习训练中至关重要的参数，很多时候一个合适的学习率才能发挥出模型的较大潜力。所以学习率调整策略同样至关重要，这篇博客介绍一下Pytorch中常见的学习率调整方法。 1.steplr这是最简单常用的学习率调整方法，每过step_size轮，将此前的学习率乘以gamma。 1scheduler=lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1) 2. MultiStepLRMultiStepLR同样也是一个非常常见的学习率调整策略，它会在每个milestone时，将此前学习率乘以gamma。 1scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.5) 3. ExponentialLRExponentialLR是指数型下降的学习率调节器，每一轮会将学习率乘以gamma，所以这里千万注意gamma不要设置的太小，不然几轮之后学习率就会降到0。 1scheduler=lr_scheduler.ExponentialLR(optimizer, gamma=0.9) 4. LinearLRLinearLR是线性学习率，给定起始factor和最终的factor，LinearLR会在中间阶段做线性插值，比如学习率为0.1，起始factor为1，最终的factor为0.1，那么第0次迭代，学习率将为0.1，最终轮学习率为0.01。下面设置的总轮数total_iters为80,所以超过80时，学习率恒为0.01。 1scheduler=lr_scheduler.LinearLR(optimizer,start_factor=1,end_factor=0.1,total_iters=80) 5. OneCycleLROneCycleLR顾名思义就像是CyclicLR的一周期版本，它也有多个参数，max_lr就是最大学习率，pct_start是学习率上升部分所占比例，一开始的学习率为max_lr&#x2F;div_factor,最终的学习率为max_lr&#x2F;final_div_factor，总的迭代次数为total_steps。 1scheduler=lr_scheduler.OneCycleLR(optimizer,max_lr=0.1,pct_start=0.5,total_steps=120,div_factor=10,final_div_factor=10) 6. CosineAnnealingLRCosineAnnealingLR是余弦退火学习率，T_max是周期的一半，最大学习率在optimizer中指定，最小学习率为eta_min。这里同样能够帮助逃离鞍点。值得注意的是最大学习率不宜太大，否则loss可能出现和学习率相似周期的上下剧烈波动。 1scheduler=lr_scheduler.CosineAnnealingLR(optimizer,T_max=20,eta_min=0.05)","categories":[],"tags":[{"name":"提点","slug":"提点","permalink":"http://localhost:4000/tags/%E6%8F%90%E7%82%B9/"}]},{"title":"脑PET图像分析和疾病预测挑战赛","slug":"nao","date":"2023-08-14T13:48:55.000Z","updated":"2023-08-15T02:00:11.116Z","comments":true,"path":"post/24840.html","link":"","permalink":"http://localhost:4000/post/24840.html","excerpt":"","text":"脑PET图像分析和疾病预测挑战赛一、赛事背景脑PET全称为脑部正电子发射计算机断层显像(brain positron emission tomography PET)，是反映脑部病变的基因、分子、代谢及功能状态的显像。它是利用正电子核素标记葡萄糖等人体代谢物作为显像剂，通过病灶对显像剂的摄取来反映其代谢变化，从而为临床提供疾病的生物代谢信息，为脑癫痫病、脑肿瘤、帕金森病、阿尔茨海默综合征等提供了有效的检测手段。可利用脑PET图像检测出轻度认知障碍病灶，并提前介入治疗，从而延缓发病，对后续患者康复治疗有着积极的意义。因此本赛题以轻度认知障碍为例对脑PET图像进行分析与疾病预测。 二、赛事任务为研究基于脑PET图像的疾病预测，本次大赛提供了海量脑PET数据集作为脑PET图像检测数据库的训练样本，参赛者需根据提供的样本构建模型，对轻度认知障碍进行分析和预测。 脑PET图像检测数据库，记录了老年人受试志愿者的脑PET影像资料，其中包括确诊为轻度认知障碍（MCI）患者的脑部影像数据和健康人（NC）的脑部影像数据。 被试者按医学诊断分为两类： NC：健康 MCI：轻度认知障碍 三、 评审规则1.数据说明本次大赛所用脑PET图像检测数据库，图像格式为nii。 表1.大赛数据库 2.评估指标本次竞赛的评价标准采用F1_score，分数越高，效果越好。 问题在基准测试中遇到 以上错误该错误产生的原因是loss接接收到的标签文件应该是 longtensor 类型的数据，但在示例代码中 12345if self.transform is not None: img = self.transform(image = img)[&#x27;image&#x27;]img = img.transpose([2,0,1])return img,torch.from_numpy(np.array(int(&#x27;NC&#x27; in self.img_path[index]))) 返回的标签为tensor类型。要将其改为 1return img, torch.tensor(int(&#x27;NC&#x27; in self.img_path[index]), dtype=torch.long) 将返回的标签转变为longtensor的类型","categories":[],"tags":[]},{"title":"卷积计算量","slug":"卷积计算量的计算","date":"2023-08-14T13:48:55.000Z","updated":"2023-08-14T13:53:11.021Z","comments":true,"path":"post/24840.html","link":"","permalink":"http://localhost:4000/post/24840.html","excerpt":"","text":"卷积计算量的计算普通卷积当计算一个神经网络模型的 FLOPs 时，让我们以一个简化的卷积神经网络（CNN）为例。假设我们有一个包含两个卷积层和一个全连接层的模型。 假设模型的结构如下： 卷积层1：输入特征图大小为 32x32，卷积核大小为 3x3，输出通道数为 64。 池化层：最大池化，池化核大小为 2x2。 卷积层2：输入特征图大小为 16x16，卷积核大小为 3x3，输出通道数为 128。 全连接层：输入特征数为 128，输出特征数为 10。 我们将使用以下计算公式来估计 FLOPs： 对于卷积层，FLOPs &#x3D; 输入特征图大小 × 卷积核大小 × 输出通道数。 对于全连接层，FLOPs &#x3D; 输入特征数 × 输出特征数。 我们假设浮点运算包括乘法和加法。 卷积层1的 FLOPs： FLOPs &#x3D; 32x32x3x3x64 &#x3D; 1,179,648 池化层不涉及大量浮点运算，可以忽略。 卷积层2的 FLOPs： FLOPs &#x3D; 16x16x3x3x128 &#x3D; 1,179,648 全连接层的 FLOPs： FLOPs &#x3D; 128x10 &#x3D; 1,280 总的 FLOPs： 1,179,648 + 1,179,648 + 1,280 &#x3D; 2,360,576 所以，这个简化的模型的总 FLOPs 为约 2.36 百万次浮点运算。请注意，这只是一个简化的示例，实际的计算可能会更复杂，因为它还需要考虑其他层、操作和参数的影响。 深度可分离卷积深度可分离卷积是一种常用于轻量级神经网络中的卷积操作，它将标准卷积拆分为深度卷积（Depthwise Convolution）和逐点卷积（Pointwise Convolution）。计算深度可分离卷积的 FLOPs 需要考虑这两个阶段的计算量。 以下是计算深度可分离卷积 FLOPs 的一般步骤： 计算深度卷积的 FLOPs： 深度卷积的计算量与输入通道数、卷积核大小、输出通道数和特征图大小有关。 对于输入通道数为 Cin，卷积核大小为 K，输出通道数为 Cout，特征图大小为 HxW（高度x宽度），深度卷积的 FLOPs 可以计算为 FLOPs_depthwise = Cin x K x K x H x W x Cout。 计算逐点卷积的 FLOPs： 逐点卷积的计算量与输出通道数、特征图大小有关。 对于输出通道数为 Cout，特征图大小为 HxW，逐点卷积的 FLOPs 可以计算为 FLOPs_pointwise = H x W x Cout。 总的 FLOPs： 深度可分离卷积的总 FLOPs 可以计算为 FLOPs_total = FLOPs_depthwise + FLOPs_pointwise。 这个计算过程可以帮助您估计深度可分离卷积的计算量。请注意，实际计算可能会因为批次大小、步幅等因素而有所不同，而且在深度学习框架中，使用内置的工具来计算 FLOPs 会更准确和方便。一些框架（如TensorFlow、PyTorch等）提供了用于估计模型计算量的功能。如果您想获得更精确的计算结果，建议使用这些工具来计算深度可分离卷积的 FLOPs。 组卷积组卷积（Group Convolution）是一种卷积操作的变体，它将输入特征图和卷积核分成若干组进行卷积操作。这种操作在一些神经网络中被用于提升计算效率和减少参数数量。组卷积主要应用于卷积神经网络（CNNs）中，常见于一些轻量级网络和深度可分离卷积中。 在标准的卷积操作中，每个输入通道与卷积核的所有通道进行卷积，这可能导致大量的参数和计算量。组卷积通过将输入通道和卷积核通道分成多个组，每个组内的通道进行独立的卷积操作，然后将各组的卷积结果叠加。这可以有效减少参数和计算量，特别是在需要保持较低计算量的场景中。 计算组卷积的 FLOPs（浮点运算次数）涉及以下几个步骤： 计算每个组内的卷积 FLOPs：对于每个组内的卷积，需要计算输入通道数、输出通道数、卷积核大小和特征图大小。对于输入通道数为 Cin，输出通道数为 Cout，卷积核大小为 K，特征图大小为 HxW，每个组内的卷积 FLOPs 可以计算为 FLOPs_group = Cin_group x K x K x H x W x Cout_group。 计算总的 FLOPs：将各个组内的卷积 FLOPs 相加，得到组卷积的总 FLOPs。 需要注意的是，组卷积可能会在一些网络架构中对不同的通道进行分组，以减少参数量和计算量。具体的分组策略可以根据网络结构和任务需求进行调整。 组卷积是一种可以用于优化卷积神经网络的技术，适用于需要减少参数和计算量的情况。在使用时，可以结合深度学习框架提供的工具来计算具体的 FLOPs，以便更准确地了解组卷积对模型计算量的影响。v s","categories":[],"tags":[]},{"title":"cv","slug":"index","date":"2023-08-07T14:45:47.000Z","updated":"2023-08-11T04:39:58.701Z","comments":true,"path":"post/5801.html","link":"","permalink":"http://localhost:4000/post/5801.html","excerpt":"","text":"【Datawhale CV夏令营】 1 Baseline的基本改进 (I)1 赛题重述1.1 赛题背景机器虽然被大量用到农业生产中，但人还是不可或缺的因素。通过农民身份识别，可以真实客观地记录农民的状态，为农场管理和农产品追溯提供真实的客观数据；较之直接存储视频，可以有效地降低存储空间；自动识别也比人工监管，大幅度提高效率，减少人工成本。 2.2 赛事任务农民身份识别需要对农民进行分类，本次大赛提供了中国农业大学实验室视频制成的图像序列。参赛选手先对图像进行预处理，并制作样本，对图像中的农民进行识别。选手需要自行训练模型，并上传自己训练好的模型和权重。 3.3 赛题数据集本次比赛为参赛选手提供了25名农民身份，每个身份包含10段视频制成的图像序列，选手需要对图像序列进行预处理，打标签，并对农民进行身份识别。 1.4 评价指标本模型依据提交的结果文件，采用Macro-F1进行评价，其中Macro-F1定义如下： 2 Baseline2.1 传统图像特征提取方法通过计算图像中的一些统计指标，如白色像素数目、均值、方差等指标手动构建特征，然后使用机器学习模型进行分类。在此不再赘述。 2.2 深度学习方法采用预训练Resnet18作为骨架，输入为图片，输出为分类结果，如下图所示 3 改进Baseline3.1 梯度裁剪对于模型fθ、度量指标L、输入数据x、对应的标签y和学习率η，有梯度更新 在训练过程中，有可能出现梯度过大导致的震荡情况。因此考虑限制梯度的范数为一定范围，这与信赖域算法思路相似： 这样的操作可以通过paddle.nn.ClipGradByNorm或torch.nn.utils.ClipGradNorm实现。 3.2 集成学习集成学习的思路较为简单，若某一个预测器件的准确率大于50%，那么很多个这样的预测器对结果投票得出的结果准确率将会更高。在对Baseline的改进中，我们引入对某模型效能的置信度函数α⋅，并将其简单地定义为模型的验证准确率的平方根。于是当! 持有N个模型时，期望的分类结果由下面的式子给出： 4 测试结果 仅使用梯度裁剪的Baseline在训练集上训练少于5Epochs 可以在测试集上达到 50% 的准确率 使用梯度裁剪和集成学习的Baseline在训练集上训练9个模型，在测试集上可以达到近 60%的准确率","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2023-08-07T10:14:01.203Z","updated":"2023-08-11T04:14:35.881Z","comments":true,"path":"post/16107.html","link":"","permalink":"http://localhost:4000/post/16107.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"jetson_nano","slug":"jetson-nano","permalink":"http://localhost:4000/tags/jetson-nano/"},{"name":"yolo","slug":"yolo","permalink":"http://localhost:4000/tags/yolo/"},{"name":"提点","slug":"提点","permalink":"http://localhost:4000/tags/%E6%8F%90%E7%82%B9/"}]}